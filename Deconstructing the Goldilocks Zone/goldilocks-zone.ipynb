{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c495cfbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from linalg import *\n",
    "from misc import *\n",
    "from models import *\n",
    "from models.utils import get_layer_idxs\n",
    "from evaluate import *\n",
    "from data import *\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (6.5,4.5)\n",
    "font = {'family': 'sans-serif','size': 18}\n",
    "mpl.rc('font', **font)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:0')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "print(f'[device: {device} is ready]')\n",
    "\n",
    "data = Circles(\n",
    "    path='data/downloads',\n",
    "    to_transform=False)\n",
    "\n",
    "model = Demo(\n",
    "    device=device,\n",
    "    in_shape=data.in_shape,\n",
    "    num_classes=data.num_classes,\n",
    "    temperature=1,\n",
    "    dtype=torch.float64,\n",
    "    activation='ReLU')\n",
    "\n",
    "w = get_trainable_parameters(model)\n",
    "idxs = get_layer_idxs(model)\n",
    "num_layers = len(idxs)\n",
    "\n",
    "seeds = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff060b8",
   "metadata": {},
   "source": [
    "## Recreating the Goldilocks Zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f419fe97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# By scaling the initialization\n",
    "\n",
    "model.set_temperature(1.)\n",
    "scales = 10**np.arange(-3,3.25,0.25)\n",
    "curvs = np.zeros((seeds, len(scales)))\n",
    "\n",
    "for seed in range(seeds):\n",
    "    for scale_id in tqdm(range(len(scales))):\n",
    "        set_trainable_parameters(model, scales[scale_id]*w)\n",
    "        _, curv = goldilocks(model, data.datasets[\"train\"], 50, device)\n",
    "        curvs[seed][scale_id] = curv\n",
    "        \n",
    "plt.plot(curvs.mean(0), color='cornflowerblue', linewidth=2)\n",
    "plt.xticks(\n",
    "        range(len(scales))[::3],\n",
    "        [round(np.log10(scale),0) for scale in scales][::3],\n",
    "        rotation=45)\n",
    "plt.xlabel('initialization scale (alpha)')\n",
    "plt.ylabel('positive curvature')\n",
    "plt.grid(ls='dashed', color='grey', alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ea605e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# By scaling the softmax temperature\n",
    "\n",
    "set_trainable_parameters(model, w)\n",
    "temps = 10**np.arange(-3*num_layers,3*num_layers+0.25*num_layers,0.25*num_layers)\n",
    "curvs = np.zeros((seeds, len(scales)))\n",
    "\n",
    "for seed in range(seeds):\n",
    "    for temp_id in tqdm(range(len(temps))):\n",
    "        model.set_temperature(temps[temp_id])\n",
    "        _, curv = goldilocks(model, data.datasets[\"train\"], 50, device)\n",
    "        curvs[seed][temp_id] = curv\n",
    "        \n",
    "plt.plot(curvs.mean(0), color='cornflowerblue', linewidth=2)\n",
    "plt.xticks(\n",
    "        range(len(temps))[::3],\n",
    "        [round(np.log10(temp),0) for temp in temps][::3],\n",
    "        rotation=45)\n",
    "plt.xlabel('initialization scale (alpha)')\n",
    "plt.ylabel('positive curvature')\n",
    "plt.grid(ls='dashed', color='grey', alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db9656d4",
   "metadata": {},
   "source": [
    "## Gauss-Newton decomposition & spectral norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6de12ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.set_temperature(1.)\n",
    "scales = 10**np.arange(-3,3,0.25)\n",
    "R = get_random_ortho_matrix(w.numel(), 50, device).to(model.dtype)\n",
    "curvs = {\n",
    "    'G': np.zeros((seeds, len(scales))),\n",
    "    'H': np.zeros((seeds, len(scales))),\n",
    "    'Hessian': np.zeros((seeds, len(scales)))}\n",
    "norms = {\n",
    "    'G': np.zeros((seeds, len(scales))),\n",
    "    'H': np.zeros((seeds, len(scales))),\n",
    "    'Hessian': np.zeros((seeds, len(scales)))}\n",
    "\n",
    "for seed in range(seeds):\n",
    "    for scale_id in tqdm(range(len(scales))):\n",
    "        set_trainable_parameters(model, scales[scale_id]*w)\n",
    "        J = get_Jacobian(model, data.datasets[\"train\"], data.num_classes, R)\n",
    "        p = F.softmax(model.predict(data.datasets[\"train\"]), dim=-1).detach()\n",
    "        G_term = get_G_term(J, p)\n",
    "        L_G = torch.real(torch.linalg.eig(G_term)[0])\n",
    "        curvs['G'][seed][scale_id] = L_G.sum()/L_G.norm() if L_G.norm()>0 else 0\n",
    "        norms['G'][seed][scale_id] = L_G.max()\n",
    "        Hessian = hessian(model, data.datasets[\"train\"], True, R)\n",
    "        L_Hessian = torch.real(torch.linalg.eig(Hessian)[0])\n",
    "        curvs['Hessian'][seed][scale_id] = L_Hessian.sum()/L_Hessian.norm()\n",
    "        norms['Hessian'][seed][scale_id] = L_Hessian.max()\n",
    "        H_term = Hessian - G_term\n",
    "        L_H = torch.real(torch.linalg.eig(H_term)[0])\n",
    "        curvs['H'][seed][scale_id] = L_H.sum()/L_H.norm()\n",
    "        norms['H'][seed][scale_id] = L_H.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae477ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Positive curvature of the G-term, H-term, and the Hessian\n",
    "\n",
    "plt.plot(curvs['Hessian'].mean(0), color='navy', linewidth=5, label='Hessian')\n",
    "plt.plot(curvs['G'].mean(0), color='cornflowerblue', linewidth=2, label='G-term')\n",
    "plt.plot(curvs['H'].mean(0), color='violet', linewidth=2, label='H-term')\n",
    "plt.xticks(\n",
    "        range(len(scales))[::3],\n",
    "        [round(np.log10(scale),0) for scale in scales][::3],\n",
    "        rotation=45)\n",
    "plt.xlabel('initialization scale (alpha)')\n",
    "plt.ylabel('positive curvature')\n",
    "plt.grid(ls='dashed', color='grey', alpha=0.5)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915a451c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spectral norm of the G-term, H-term, and the Hessian\n",
    "\n",
    "plt.plot(norms['Hessian'].mean(0), color='navy', linewidth=5, label='Hessian')\n",
    "plt.plot(norms['G'].mean(0), color='cornflowerblue', linewidth=2, label='G-term')\n",
    "plt.plot(norms['H'].mean(0), color='violet', linewidth=2, label='H-term')\n",
    "plt.xticks(\n",
    "        range(len(scales))[::3],\n",
    "        [round(np.log10(scale),0) for scale in scales][::3],\n",
    "        rotation=45)\n",
    "plt.xlabel('initialization scale (alpha)')\n",
    "plt.ylabel('spectral norm')\n",
    "plt.grid(ls='dashed', color='grey', alpha=0.5)\n",
    "plt.legend()\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470a3ee0",
   "metadata": {},
   "source": [
    "## Expected G-term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5edd24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.set_temperature(1.)\n",
    "scales = 10**np.arange(-3,3,0.25)\n",
    "curvs_G = np.zeros((seeds, len(scales)))\n",
    "curvs_EG = np.zeros((seeds, len(scales)))\n",
    "R = get_random_ortho_matrix(w.numel(), 50, device).to(model.dtype)\n",
    "\n",
    "for seed in range(seeds):\n",
    "    for scale_id in tqdm(range(len(scales))):\n",
    "        set_trainable_parameters(model, scales[scale_id]*w)\n",
    "        J = get_Jacobian(model, data.datasets[\"train\"], data.num_classes, R)\n",
    "        p = F.softmax(model.predict(data.datasets[\"train\"]), dim=-1).detach()\n",
    "        var_C = (J.mean(0).std([0,1]))**2\n",
    "        cs = J.mean(0, keepdim=True)\n",
    "        cs = cs.repeat(J.shape[0],1,1)\n",
    "        var_E = ((J-cs).std([0,1,2]))**2\n",
    "        G_term = get_G_term(J, p)\n",
    "        L_G = torch.real(torch.linalg.eig(G_term)[0])\n",
    "        curvs_G[seed][scale_id] = L_G.sum()/L_G.norm() if L_G.norm()>0 else 0 \n",
    "        curvs_EG[seed][scale_id] = EG_curvature(var_E, var_C, R.shape[0], p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a64696",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Positive curvature of the empirical G-term and the expected G-term\n",
    "\n",
    "plt.plot(curvs_G.mean(0), color='dodgerblue', linewidth=2, label='G')\n",
    "plt.plot(curvs_EG.mean(0), color='crimson', linewidth=2, label='EG')\n",
    "plt.xticks(\n",
    "        range(len(scales))[::3],\n",
    "        [round(np.log10(scale),0) for scale in scales][::3],\n",
    "        rotation=45)\n",
    "plt.xlabel('initialization scale (alpha)')\n",
    "plt.ylabel('positive curvature')\n",
    "plt.grid(ls='dashed', color='grey', alpha=0.5)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0785cbc6",
   "metadata": {},
   "source": [
    "## Expected gradient & more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3185eb64",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 500\n",
    "model.set_temperature(1.)\n",
    "set_trainable_parameters(model, w)\n",
    "\n",
    "R = get_random_ortho_matrix(w.numel(), 50, device).to(model.dtype)\n",
    "J = get_Jacobian(model, data.datasets[\"train\"], data.num_classes, R)\n",
    "var_C = (J.mean(0).std([0,1]))**2\n",
    "Q = get_prior(data.datasets[\"train\"].targets, data.num_classes)\n",
    "\n",
    "g_norms = np.zeros((num_samples,))\n",
    "prior_dist = np.zeros((num_samples,))\n",
    "losses = np.zeros((num_samples,))\n",
    "avg_entropy = np.zeros((num_samples,))\n",
    "curvs = np.zeros((num_samples,))\n",
    "\n",
    "for i in tqdm(range(num_samples)):\n",
    "    model.zero_grad()\n",
    "    model.initialize()\n",
    "    out = model.predict(data.datasets[\"train\"])\n",
    "    p = F.softmax(out, dim=-1).detach().cpu()\n",
    "    avg_entropy[i] = Categorical(p).entropy().mean(0)\n",
    "    loss = F.cross_entropy(out, data.datasets[\"train\"].targets.to(device))\n",
    "    loss.backward()\n",
    "    losses[i] = loss.item()\n",
    "    g = get_current_gradients(model).detach()\n",
    "    g_norms[i] = g.norm()\n",
    "    prior_dist[i] = (Q-p.mean(0)).norm()\n",
    "    curv = goldilocks(model, data.datasets[\"train\"], 50, device)[1]\n",
    "    curvs[i] = curv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1bd8fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient norms vs. prior mismatch\n",
    "\n",
    "plt.scatter(prior_dist, g_norms, s=10, color='grey')\n",
    "plt.plot([0,prior_dist.max()],[0, R.shape[1]*np.sqrt(var_C)*prior_dist.max()], color='purple', label='slope from Eq. 10')\n",
    "plt.xlabel('prior mismatch')\n",
    "plt.ylabel('gradient norm')\n",
    "plt.grid(ls='dashed', color='grey', alpha=0.5)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c323b340",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The inteplay between output entropy, positive curvature, and initial loss\n",
    "\n",
    "bins = [np.quantile(losses, i) for i in np.linspace(0,1,20)]\n",
    "idxs = np.digitize(losses, bins)\n",
    "cmap = plt.get_cmap('viridis')\n",
    "colors = np.array([cmap(i) for i in np.linspace(0,1,len(bins)+1)])\n",
    "plt.scatter(avg_entropy, curvs, s=10, color=colors[idxs])\n",
    "plt.xlabel('avg prediction entropy')\n",
    "plt.ylabel('positive curvature')\n",
    "plt.grid(ls='dashed', color='grey', alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a0af7a",
   "metadata": {},
   "source": [
    "## Top Hessian eigenvector before softmax collapse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad55f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = FMNIST(\n",
    "    path='data/downloads',\n",
    "    to_transform=False)\n",
    "\n",
    "model = LeNet300100(\n",
    "    device=device,\n",
    "    in_shape=data.in_shape,\n",
    "    num_classes=data.num_classes,\n",
    "    temperature=1,\n",
    "    dtype=torch.float64,\n",
    "    activation='ReLU')\n",
    "\n",
    "w = get_trainable_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf649cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "scales = [5, 10, 30, 60, 100, 200]\n",
    "fig, axes = plt.subplots(ncols=len(scales), nrows=1, figsize=(10,2))\n",
    "for scale_id in tqdm(range(len(scales))):\n",
    "    set_trainable_parameters(model, scales[scale_id]*w)\n",
    "    _, V = eigenthings(\n",
    "            model=model,\n",
    "            loss=F.cross_entropy,\n",
    "            dataset=data.datasets[\"train\"],\n",
    "            num_things=1)\n",
    "    img = V.squeeze()[:784*300].reshape(300,784)\n",
    "    img = img.mean(axis=0).reshape(data.in_shape).squeeze()\n",
    "    axes[scale_id].imshow(img, cmap='viridis')\n",
    "    axes[scale_id].set_xticklabels(labels=[])\n",
    "    axes[scale_id].set_yticklabels(labels=[])\n",
    "    axes[scale_id].set_title(f'{scales[scale_id]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
